# Evaluation Results for GemMaroc and Atlas

This Excel file contains a detailed evaluation of two models — **GemMaroc** and **Atlas** — on a set of **30 prompts**.
The evaluation was performed across four criteria, with both **prompt-level** and **overall** results.

## File Structure

The workbook contains **three sheets**:

### 1. **Answers**

* Contains the **full text of the 30 prompts** used for evaluation.
* Includes the **responses from both GemMaroc and Atlas** for each prompt.
* Serves as the reference for qualitative review.

### 2. **Marks**

* Provides **prompt-by-prompt evaluation** for both models.
* Each prompt is scored across **four criteria**:

  1. **Helpfulness** (weight: 0.12)
  2. **Accuracy** (weight: 0.50)
  3. **Completeness** (weight: 0.13)
  4. **Darija Fluency** (weight: 0.25)
* The **Total** score for each prompt is a weighted sum of these criteria.
* Conditional formatting highlights performance:

  * **Green** = high score
  * **Yellow** = medium score
  * **Red** = low score

### 3. **Global\_Marks**

* Displays **average scores across all 30 prompts** for each model.
* Provides a quick comparison of **overall performance**.

## Scoring Methodology

* Scores range from **1 (poor)** to **5 (excellent)** for each criterion.
* Weighted totals are computed for each prompt and then averaged to obtain overall scores.

## Purpose

This evaluation aims to compare **GemMaroc** and **Atlas** on a diverse set of prompts, measuring:

* **Content quality**
* **Accuracy of information**
* **Completeness of responses**
* **Fluency in Moroccan Darija**

These results can be used for **model benchmarking**, **fine-tuning priorities**, and **progress tracking** over time.
